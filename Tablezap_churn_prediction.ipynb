{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**TABLEZAP CUSTOMER CHURN PREDICTION CASE STUDY**"
      ],
      "metadata": {
        "id": "JEqyMfoQZjI1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FIRST OF ALL LET'S INSTALL THE REQUIRED LIBRARY THAT IS PYSPARK FOR THE REQUIRED TABLE.**"
      ],
      "metadata": {
        "id": "W7U7-iEyZVLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG9Ac19S25KS",
        "outputId": "06bf5371-d139-4260-ff16-c40178a4ddba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=a48b8492f497b6737f66938fff8c720a174f689d64c8190a4b73f4f06a4f562e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LET'S WRITE THE CODE FOR CREATING THE SPARK SESSION, AND ALSO FOR IMPORTING THE REQUIRED FUNCTIONS SUCH AS COUNT, AVERAGE ETC.**"
      ],
      "metadata": {
        "id": "pUiMtaiEZ36G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, count, avg, datediff\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"CustomerMetrics\").getOrCreate()"
      ],
      "metadata": {
        "id": "vZ0ancUqwcU0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LET'S READ ALL THE CSV FILES WHICH ARE GIVEN IN ORDER TO GAIN ALL THE INSIGHTS FROM THE DATA AND ALSO THESE ARE REQUIRED TO MAKE THE NECESSARY COLUMNS FOR THE TABLE THAT WILL BE FURTHER USED FOR THE ANALYSIS AND ALSO FOR THE CHURN PREDICTION.**"
      ],
      "metadata": {
        "id": "LSoxMpQUbHJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the tables into Spark DataFrames\n",
        "customer_data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/content/customer_data.csv\")\n",
        "order_history = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/content/order_history.csv\")\n",
        "customer_interactions = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/content/customer_interactions.csv\")\n",
        "loyalty_program = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/content/loyalty_program.csv\")"
      ],
      "metadata": {
        "id": "gEAiibLba9iW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOW AFTER READING ALL THE CSV FILES LET'S MOVE ON TO OUR NEXT AND THE MOST IMPORTANT STEPS THAT IS MAKING OF THE CHURN PREDICTION TABLE**"
      ],
      "metadata": {
        "id": "5SPJLFD_bzPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. SO THE FIRST COLUMN THAT WE ARE GOING TO CREATE IS THE \"FREQUENCY OF VISITS\", THIS COLUMN WILL SHOW THAT, HOW MANY NUMBER OF TIMES DOES A PARTICULAR CUSTOMER ID VISITS TO THE RESTAURANT.** "
      ],
      "metadata": {
        "id": "LCOHdOc8cEcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate frequency of visits\n",
        "frequency_of_visits = order_history.groupBy(\"customer_id\").agg(count(\"*\").alias(\"frequency_of_visits\"))"
      ],
      "metadata": {
        "id": "FHUs7vhYcfmU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. NOW LET'S MOVE ON TO OUR NEXT COLUMN, WHICH IS \"AVERAGE ORDER VALUE\", THIS COLUMN WILL SHOW THAT,ON AN AVERAGE HOW MUCH ORDERS ARE PLACED BY A PARTICULAR CUSTOMER ID.**"
      ],
      "metadata": {
        "id": "7LWaYaCccijL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average order value\n",
        "average_order_value = order_history.groupBy(\"customer_id\").agg(avg(\"order_total\").alias(\"average_order_value\"))"
      ],
      "metadata": {
        "id": "nOhBByBOdDUk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. NOW LET'S WRITE THE CODE FOR THE NEXT COLUMN WHICH IS \"TIME SPENT PER VISIT\", THIS COLUMN WILL INTREPRET THAT HOW MUCH TIME DOES A PARTICULAR CUSTOMER ID SPENT IN THE RESTAURANT.**"
      ],
      "metadata": {
        "id": "Ji5flKcddVGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate time spent per visit\n",
        "time_spent_per_visit = order_history.alias(\"o\").join(\n",
        "    order_history.alias(\"o2\"),\n",
        "    (col(\"o.customer_id\") == col(\"o2.customer_id\")) & (col(\"o.order_date\") > col(\"o2.order_date\")),\n",
        "    \"left\"\n",
        ").groupBy(\"o.customer_id\", \"o.order_date\").agg(\n",
        "    avg(datediff(col(\"o.order_date\"), col(\"o2.order_date\"))).alias(\"time_spent_per_visit\")\n",
        ").groupBy(\"customer_id\").agg(avg(\"time_spent_per_visit\").alias(\"time_spent_per_visit\"))"
      ],
      "metadata": {
        "id": "IF-Y4qfKdvpX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. NOW LET'S CALCULATE OUR LAST COLUMN THAT IS \"FEEDBACK SENTIMENT\", THIS WILL GIVE US THE INFORMATION ABOUT THE AVERAGE FEEDBACK RATING BY A PARTICULAR CUSTOMER ID.**"
      ],
      "metadata": {
        "id": "OnsHG_VPesm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate feedback sentiment\n",
        "feedback_sentiment = order_history.where(col(\"feedback_rating\").isNotNull()).groupBy(\"customer_id\").agg(avg(\"feedback_rating\").alias(\"feedback_sentiment\"))"
      ],
      "metadata": {
        "id": "jCB1pjV3fAvz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SO NOW AS WE HAVE CALCULATED OUR ALL THE FOUR REQUIRED COLUMNS, LET'S MERGE THEM INTO A TABLE.**"
      ],
      "metadata": {
        "id": "Ck01IqIzfDfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Join all the metrics together\n",
        "customer_metrics = customer_data.select(\"customer_id\", \"customer_name\").join(\n",
        "    frequency_of_visits, \"customer_id\"\n",
        ").join(\n",
        "    average_order_value, \"customer_id\"\n",
        ").join(\n",
        "    time_spent_per_visit, \"customer_id\"\n",
        ").join(\n",
        "    feedback_sentiment, \"customer_id\"\n",
        ")"
      ],
      "metadata": {
        "id": "1XFuYhJAfSXB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_metrics.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb5uorz0fWjq",
        "outputId": "f78a11cc-6117-480f-ee19-972cbac49b62"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+-------------------+-------------------+--------------------+------------------+\n",
            "|customer_id|    customer_name|frequency_of_visits|average_order_value|time_spent_per_visit|feedback_sentiment|\n",
            "+-----------+-----------------+-------------------+-------------------+--------------------+------------------+\n",
            "|        691|    Matthew Moore|                  8|           2406.625|  134.89897959183673|             1.875|\n",
            "|        829|   Mary Rodriguez|                  4|            2671.75|   302.9444444444444|              3.25|\n",
            "|        296|       Mario Rush|                  5|             2180.0|  238.14583333333334|               3.0|\n",
            "|        675|     Kristy Huynh|                  2|             2905.0|               410.0|               3.0|\n",
            "|        467|    Michael Sloan|                  4|             1998.5|   245.1111111111111|               4.0|\n",
            "|        944|     Keith Harmon|                  4|             2755.5|               177.0|               4.0|\n",
            "|        800|   Gregory Holmes|                  4|            3349.75|   226.2222222222222|              3.25|\n",
            "|        853|    Richard Lopez|                  4|             1511.0|   336.8333333333333|              4.25|\n",
            "|        451|       Karina Kim|                  7|  3152.714285714286|  247.20277777777775| 2.857142857142857|\n",
            "|        125|      Jorge Blair|                  5|             2149.4|            214.1875|               2.2|\n",
            "|        926|   Audrey Coleman|                  6| 2723.1666666666665|               219.8|               2.5|\n",
            "|        666| Makayla Anderson|                 10|             3065.1|  236.36878306878305|               2.5|\n",
            "|        870|    Bobby Herring|                  8|            2990.75|  255.07448979591837|             3.125|\n",
            "|        919|Christopher Casey|                  3|             2263.0|              409.25|1.6666666666666667|\n",
            "|         51|      Sarah Ellis|                  2|             1790.5|               190.0|               2.0|\n",
            "|        124|   Rebecca Barron|                  8|           2987.875|  267.83333333333337|               3.5|\n",
            "|          7|     Erin Johnson|                  4|             2349.0|  159.72222222222223|              3.25|\n",
            "|        447| Elizabeth Hansen|                  6| 1718.3333333333333|  160.10999999999999|3.1666666666666665|\n",
            "|        591|    Ryan Bradshaw|                  3|             1422.0|              305.25|2.6666666666666665|\n",
            "|        475|   Marvin Kaufman|                  6| 2707.6666666666665|  165.70999999999998|2.6666666666666665|\n",
            "+-----------+-----------------+-------------------+-------------------+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LET'S STORE THE ABOVE TABLE IN CSV FORMAT.**"
      ],
      "metadata": {
        "id": "jjdQ-RzVfefN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Spark DataFrame to Pandas DataFrame\n",
        "customer_metrics_pandas = customer_metrics.toPandas()\n",
        "\n",
        "# Save Pandas DataFrame to an Excel file\n",
        "customer_metrics_pandas.to_csv(\"customer_metrics.csv\", index=False)\n",
        "\n",
        "# Stop the SparkSession\n",
        "spark.stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMViVXPpf3v1",
        "outputId": "e11cae6c-c275-4f63-8cef-8b4eeef6aad1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method SparkSession.stop of <pyspark.sql.session.SparkSession object at 0x7fdbd8ea25f0>>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jTKBVq684Ku4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cqAq7ggw4Kze"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}